{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks with keras\n",
    "\n",
    "Artificial Neural Networks are the state of the art of machine learning, they main appeal is very powerful and scalable. They can classify billions of \n",
    "images, understance human language... etc. In this chapter we will discuss them extensively and after that we will talk about an amelioration of them \n",
    "called multilayer perceptron.\n",
    "\n",
    "## Perceptron\n",
    "\n",
    "A Perceptron is one of the simplest types of artificial neural networks and serves as the foundation for more complex neural network models. It is often \n",
    "used for binary classification tasks. The perceptron is a linear classifier, meaning it makes decisions by finding a linear boundary that separates \n",
    "different classes of data. A perceptron consists of a single neuron. It has input features, weights, a bias, and an activation function. Its function\n",
    "by having basic units called __TLU__(Threshold Logical Unit) and every TLU is connected to each input all of this in a single layer. This type of networks are trained by mimicking the behavior of biological brains, meaning that connections that produce correct predictions are reenforced and inversely others \n",
    "that produce incorrect predictions are weakened. Here is the equation defining the learning rule:\n",
    "$$w_{i, j}^{(next step)} = w_{i, j} + \\eta (y_j + \\hat{y_j})x_i $$\n",
    "In this equation $w_{i, j}$ is the connection weight between the input _i_ and the neuron _j_, $x_i$ is the $i^{th}$ input value of the current training\n",
    "instance, $\\hat{y}$ is the output of the $j^{th}$ output neuron for the current training instance, y is the target output of the $j^{th}$ output neuron for the current training instance and $\\eta$ is the learning rate. Scikit-learn possess a _Perceptron_ class that can be used exactly like a _LogisticRegressor_\n",
    "class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = (iris.target == 0)\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "X_new = [[2, 0.5], [3, 1]]\n",
    "print(per_clf.predict(X_new))\n",
    "# We can do the same thing with a SGDClassifier by setting its loss parameter to \"perceptron\", learning_rate to \"constant\" and eta0=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proeminent problem with perceptron is that they are incapable of solving basic problems such as the exclusive OR(XOR). To mitigate this problem the\n",
    "solution is to simply stack multiple layers of them which bring the topic of __multilayer perceptrons(MLP)__.\n",
    "\n",
    "## Multilayer Perceptron and Backpropagation\n",
    "\n",
    "A MLP is composed of one layer of inputs, one or more layers of TLU (called the _hidden layer_) and an output layer. The way to train a MLP is to use the\n",
    "algorithm called __reverse mode automatic differentiation__, it computes the gradient of the neural network's error taking into account all the model's\n",
    "parameters. Meaning its find the best value for the connection weights and bias to apply in order to obtain an optimal model. At the end of the process, we\n",
    "can use this gradients to perform a gradient descent step which will gradually drop the error rate of the model until it reaches a minimum. This process\n",
    "is called _backpropagation_. Let's look at how the backpropagation is performed step by step in details:\n",
    "- It handles one mini-batch at a time and goes through the whole training set multiple times (each loop is called an _epoch_).\n",
    "- Each mini-batch become the input layer and they are passed trough the hidden layers similarly to how we would make predictions except all the intermediate\n",
    " results are kept for the backward pass. This phase is called the _forward pass_.\n",
    "- The algorithm measure the error by using a cost function that compares the output(s) to the desired output(s).\n",
    "- Then it computes how much each bias and weight contribute to the error rate by following a concept known as the _chain rule_.\n",
    "- After that the algorithm try to measure how much of the error is contributed by the layers(still using the chain rule) working its way backward until\n",
    " it comes back to the input layer. This reverse pass efficiently measures the error gradient across all the connection weights and biases in the network by \n",
    " propagating the error gradient backward through the network. This is the _backward pass_.\n",
    "- Finally the algorithm perform gradient descent to tweak the parameters using the error gradient computed earlier.\n",
    "\n",
    "__Side Note__: For the first pass of course we should initialize the inputs weights randomly and the bias term at 0 (or randomly both are fine).  \n",
    "In order for backpropagation to work, the step function have to be swapped to the logistic function(also called the sigmoid function):\n",
    "$$\\sigma(z) = \\frac{1}{1 + \\exp(-z)} $$\n",
    "But it can work with other activation function other than this one such as:\n",
    "- The hyperbolic tangent function:\n",
    " $$\\tanh(z) = 2\\sigma (2z) - 1 $$\n",
    "- The rectified linear unit function (__ReLU__):\n",
    " $$ReLU(z) = \\max(0, z) $$\n",
    "\n",
    "### Regression tasks with MLPs\n",
    "\n",
    "Scikit-Learn includes an MLPRegressor class, we can use it to build an MLP with 3 hidden layers composed of 50 neurons each, and train it on our housing\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on the validation set: [1.28463736 2.3567012  1.37453837 ... 2.00380092 1.63780066 1.98379911]\n",
      "Error rate on the predictions: 0.505332665796845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_reg)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "rmse = root_mean_squared_error(y_valid, y_pred)\n",
    "\n",
    "print(f\"Prediction on the validation set: {y_pred}\")\n",
    "print(f\"Error rate on the predictions: {rmse}\") # Error rate we will be similar to a random forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Side Note__: We did not use any activation function here so the mlp can output any value, but if we wanted it to only output a positive value then we could use ReLU as activation function or its smoothed variant called _softplus_:\n",
    "$$softplus(z) = \\log(1 + \\exp(z)) $$\n",
    "Softplus's output is close to zero when z is negative and close to z when z is positive. We should also note that _MLPRegressor_ does not support to be\n",
    "passed an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with MLPs\n",
    "\n",
    "We can also use MLPs for classification problems (from a simple binary classification to a multilabel binary classification). Scikit-Learn has an \n",
    "_MLPClassifier_ class in the _sklearn.neural\\_network_ package. It is almost identical to the MLPRegressor class, except that it minimizes the cross \n",
    "entropy rather than the MSE. It’s almost a linear task, so a single layer with 5 to 10 neurons should suffice (make sure to scale the features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP with Keras using the Sequential API\n",
    "\n",
    "Let' demonstrate how to use this library by building an image classification algorithm for that we will use the MNIST fashion dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "\n",
    "# To simplify we are going to scale the pixel intensity to 0-1 range\n",
    "X_train, X_valid, X_test = X_train / 255, X_valid / 255, X_test / 255\n",
    "\n",
    "# Now we are going to build the model using 2 hidden layers\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=[28, 28]))\n",
    "model.add(tf.keras.layers.Flatten()) # The flatten layer just reshape the 28x28 image into a 1D array\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "# Alternatively we can pass the list of layers directly when creating the sequential model\n",
    "\"\"\"\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\"\"\"\n",
    "# Now we must compile the model in order to specify the loss function, optimizer and other metrics we would want to have\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function we have chosen to use is the sparse categorical crossentropy because the target values are sparse(they are mutually exclusive) as for the\n",
    "optimizer we use \"sgd\" which means it will use schotastic gradient descent after the backpropagation(other optimizers more performant exist). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6815 - loss: 0.9750 - val_accuracy: 0.8260 - val_loss: 0.5067\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8270 - loss: 0.5053 - val_accuracy: 0.8364 - val_loss: 0.4521\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8439 - loss: 0.4516 - val_accuracy: 0.8412 - val_loss: 0.4285\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8538 - loss: 0.4207 - val_accuracy: 0.8488 - val_loss: 0.4135\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8599 - loss: 0.3985 - val_accuracy: 0.8520 - val_loss: 0.4027\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8657 - loss: 0.3811 - val_accuracy: 0.8564 - val_loss: 0.3934\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8713 - loss: 0.3667 - val_accuracy: 0.8584 - val_loss: 0.3876\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8753 - loss: 0.3548 - val_accuracy: 0.8608 - val_loss: 0.3816\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8786 - loss: 0.3442 - val_accuracy: 0.8640 - val_loss: 0.3751\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8823 - loss: 0.3346 - val_accuracy: 0.8658 - val_loss: 0.3727\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8847 - loss: 0.3258 - val_accuracy: 0.8664 - val_loss: 0.3678\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8878 - loss: 0.3178 - val_accuracy: 0.8684 - val_loss: 0.3642\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8898 - loss: 0.3102 - val_accuracy: 0.8702 - val_loss: 0.3606\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8917 - loss: 0.3032 - val_accuracy: 0.8712 - val_loss: 0.3579\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8939 - loss: 0.2966 - val_accuracy: 0.8712 - val_loss: 0.3553\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8962 - loss: 0.2902 - val_accuracy: 0.8718 - val_loss: 0.3530\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8982 - loss: 0.2842 - val_accuracy: 0.8730 - val_loss: 0.3507\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9001 - loss: 0.2786 - val_accuracy: 0.8718 - val_loss: 0.3493\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9028 - loss: 0.2733 - val_accuracy: 0.8718 - val_loss: 0.3492\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9045 - loss: 0.2680 - val_accuracy: 0.8724 - val_loss: 0.3487\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 0.9061 - loss: 0.2629 - val_accuracy: 0.8746 - val_loss: 0.3463\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.9081 - loss: 0.2581 - val_accuracy: 0.8756 - val_loss: 0.3462\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 7ms/step - accuracy: 0.9099 - loss: 0.2534 - val_accuracy: 0.8756 - val_loss: 0.3458\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9121 - loss: 0.2488 - val_accuracy: 0.8756 - val_loss: 0.3438\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9140 - loss: 0.2444 - val_accuracy: 0.8762 - val_loss: 0.3438\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9150 - loss: 0.2400 - val_accuracy: 0.8772 - val_loss: 0.3445\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9170 - loss: 0.2360 - val_accuracy: 0.8764 - val_loss: 0.3457\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9184 - loss: 0.2320 - val_accuracy: 0.8764 - val_loss: 0.3468\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9203 - loss: 0.2281 - val_accuracy: 0.8760 - val_loss: 0.3474\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9215 - loss: 0.2245 - val_accuracy: 0.8772 - val_loss: 0.3459\n"
     ]
    }
   ],
   "source": [
    "# Now we can train the model\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The history object the model returns a History object containing the training parameters (_history.params_), the list of epochs it went through \n",
    "(_history.epoch_), and most importantly a dictionary (_history.history_) containing the loss and extra metrics it measured at the end of each epoch on the \n",
    "training set and on the validation set. If we plot this dataframe we obtain the learning curve of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5), xlim=[0, 29], ylim=[0, 1], grid=True, xlabel=\"Epoch\", style=[\"r--\", \"r--.\", \"b-\", \"b-*\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can observe that the model perform a bit better on the training set than on the validation set (which means that a little bit of overfitting is \n",
    "taking place)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression tasks with the Sequential API\n",
    "\n",
    "Let's build the a neural net and test it on the housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Notes\\handsonml\\mlnotes\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - RootMeanSquaredError: 3.0623 - loss: 9.4595 - val_RootMeanSquaredError: 2.9013 - val_loss: 8.4177\n",
      "Epoch 2/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - RootMeanSquaredError: 2.8836 - loss: 8.3152 - val_RootMeanSquaredError: 2.8998 - val_loss: 8.4088\n",
      "Epoch 3/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - RootMeanSquaredError: 2.8787 - loss: 8.2868 - val_RootMeanSquaredError: 2.9001 - val_loss: 8.4107\n",
      "Epoch 4/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - RootMeanSquaredError: 2.8769 - loss: 8.2767 - val_RootMeanSquaredError: 2.8979 - val_loss: 8.3981\n",
      "Epoch 5/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - RootMeanSquaredError: 2.8759 - loss: 8.2710 - val_RootMeanSquaredError: 2.8964 - val_loss: 8.3892\n",
      "Epoch 6/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - RootMeanSquaredError: 2.8751 - loss: 8.2663 - val_RootMeanSquaredError: 2.8954 - val_loss: 8.3836\n",
      "Epoch 7/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - RootMeanSquaredError: 2.8746 - loss: 8.2636 - val_RootMeanSquaredError: 2.8943 - val_loss: 8.3770\n",
      "Epoch 8/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - RootMeanSquaredError: 2.8742 - loss: 8.2608 - val_RootMeanSquaredError: 2.8932 - val_loss: 8.3706\n",
      "Epoch 9/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - RootMeanSquaredError: 2.8737 - loss: 8.2581 - val_RootMeanSquaredError: 2.8941 - val_loss: 8.3761\n",
      "Epoch 10/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - RootMeanSquaredError: 2.8735 - loss: 8.2572 - val_RootMeanSquaredError: 2.8928 - val_loss: 8.3683\n",
      "Epoch 11/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - RootMeanSquaredError: 2.8730 - loss: 8.2541 - val_RootMeanSquaredError: 2.8926 - val_loss: 8.3669\n",
      "Epoch 12/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - RootMeanSquaredError: 2.8726 - loss: 8.2518 - val_RootMeanSquaredError: 2.8926 - val_loss: 8.3671\n",
      "Epoch 13/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - RootMeanSquaredError: 2.8722 - loss: 8.2493 - val_RootMeanSquaredError: 2.8928 - val_loss: 8.3684\n",
      "Epoch 14/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - RootMeanSquaredError: 2.8719 - loss: 8.2479 - val_RootMeanSquaredError: 2.8929 - val_loss: 8.3691\n",
      "Epoch 15/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - RootMeanSquaredError: 2.8717 - loss: 8.2467 - val_RootMeanSquaredError: 2.8930 - val_loss: 8.3696\n",
      "Epoch 16/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - RootMeanSquaredError: 2.8715 - loss: 8.2457 - val_RootMeanSquaredError: 2.8931 - val_loss: 8.3699\n",
      "Epoch 17/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - RootMeanSquaredError: 2.8715 - loss: 8.2454 - val_RootMeanSquaredError: 2.8931 - val_loss: 8.3702\n",
      "Epoch 18/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - RootMeanSquaredError: 2.8713 - loss: 8.2446 - val_RootMeanSquaredError: 2.8931 - val_loss: 8.3701\n",
      "Epoch 19/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - RootMeanSquaredError: 2.8712 - loss: 8.2440 - val_RootMeanSquaredError: 2.8932 - val_loss: 8.3705\n",
      "Epoch 20/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - RootMeanSquaredError: 2.8712 - loss: 8.2436 - val_RootMeanSquaredError: 2.8932 - val_loss: 8.3708\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 2.8625 - loss: 8.1943\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer, # This does the same thing as a StandardScaler\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Althought the sequential model is pretty popular sometime we will need to use more complex models. \n",
    "\n",
    "### Building complex models using the functional API\n",
    "\n",
    "The algorithm works by connecting all or part of the input layer to the output layer. This method makes the algorithm more prone to learning simpler\n",
    "patterns because the data will not have to go through all this transformation(this is called the _wide path_), but also the hidden layers will be in \n",
    "charge of finding the more complex patterns(this is called the _deep path_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Normalization()\n",
    "hidden_layer1 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "hidden_layer2 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "concat_layer = tf.keras.layers.Concatenate()\n",
    "output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "input_ = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "normalized = normalization_layer(input_)\n",
    "hidden1 = hidden_layer1(normalized)\n",
    "hidden2 = hidden_layer2(hidden1)\n",
    "concat = concat_layer([normalized, hidden2])\n",
    "\n",
    "output = output_layer(concat)\n",
    "model = tf.keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we want to pass a subset of the features through the deep path and another subset of features through the wide path, here is the solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wide = tf.keras.layers.Input(shape=[5])\n",
    "input_deep = tf.keras.layers.Input(shape=[6])\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the subclassing API to build dynamic models\n",
    "\n",
    "The models we have built so far fits most purposes but sometimes we may need to be able to customize their behavior. For that keras gives us the Model\n",
    "subclass where we can create our layers in, and specify the computations we want it to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a copycat of the functional model from earlier\n",
    "class WideAndDeepModel(tf.keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super.__init__(**kwargs)\n",
    "        self.norm_layer_wide = tf.keras.layers.Normalization()\n",
    "        self.norm_layer_deep = tf.keras.layers.Normalization()\n",
    "        self.hidden1 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = tf.keras.layers.Dense(1)\n",
    "        self.aux_output = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_wide, input_deep = inputs\n",
    "        norm_wide = self.norm_layer_wide(input_wide)\n",
    "        norm_deep = self.norm_layer_deep(input_deep)\n",
    "        hidden1 = self.hidden1(norm_deep)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "        output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return output, aux_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models\n",
    "\n",
    "Saving the model in the filesystem is very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'my_model.tf'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 5), dtype=tf.float32, name='keras_tensor_34'), TensorSpec(shape=(None, 6), dtype=tf.float32, name='keras_tensor_35')]\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2656082283984: TensorSpec(shape=(1, 6), dtype=tf.float32, name=None)\n",
      "  2656082281104: TensorSpec(shape=(1, 6), dtype=tf.float32, name=None)\n",
      "  2656082282640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2656082285520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2656082283792: TensorSpec(shape=(1, 5), dtype=tf.float32, name=None)\n",
      "  2656082283216: TensorSpec(shape=(1, 5), dtype=tf.float32, name=None)\n",
      "  2656082286288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2656082286864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2656082287056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2656082287632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model.keras\") # Both works fine\n",
    "model.export(\"my_model.tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load a saved model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"my_model.tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning neural networks\n",
    "\n",
    "One way to determine the best set of hyperparameters to use in a keras neural network is to convert it into a scikit-learn classifier or regressor and \n",
    "use _GridSearchCV_ or _RandomSearchCV_. For that we can use the _KerasClassifier()_ or _KerasRegressor()_ class wrapper. Another way is to use a librairy\n",
    "called _keras\\_tuner_. After installing the package, we need to write the function that build, train and returns the model. Note that this function needs\n",
    "to take a _keras_tuner.Hyperparameters_ object imperatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp: kt.HyperParameters):\n",
    "    n_hidden = hp.Int(\"n_hidden\", max_value=8, min_value=0, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.Optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.Optimizers.Adam(learning_rate=learning_rate)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Hidden(n_neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Now we can use a basic random search\n",
    "random_search_tuner = kt.RandomSearch(build_model, objective=\"val_accuracy\", max_trials=5, overwrite=True, directory=\"my_fashion_mnist\", project_name=\"my_rnd_search\", seed=42)\n",
    "random_search_tuner.search(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "# Now we can search for the 3 best models\n",
    "top3_models = random_search_tuner.get_best_models(num_models=3)\n",
    "best_model = top3_models[0]\n",
    "top3_params = random_search_tuner.get_best_hyperparameters(num_trials=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlnotes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
